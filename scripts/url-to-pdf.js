import { readFileSync } from 'fs'
import { dirname, join } from 'path'
import { chromium } from 'playwright'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)
const outputDir = __dirname + '/../pdfs/'

/**
 * read article data from latest-raw.json file
 * @returns {Array} article array with full data
 */
function getArticlesFromJson() {
	try {
		const jsonPath = join(__dirname, '../data/latest-raw.json')
		const jsonData = readFileSync(jsonPath, 'utf8')
		const data = JSON.parse(jsonData)

		if (!data.articles || !Array.isArray(data.articles)) {
			throw new Error('JSON file does not contain articles array')
		}

		console.log(`ğŸ“– Read ${data.articles.length} articles from latest-raw.json`)
		return data.articles
	} catch (error) {
		console.error('âŒ Failed to read latest-raw.json:', error.message)
		throw error
	}
}

/**
 * format timestamp for display using UTC time
 * @param {Date} date - Date object
 * @returns {string} formatted timestamp in UTC
 */
function formatTimestamp(date) {
	return (
		date.toLocaleString('en-US', {
			year: 'numeric',
			month: '2-digit',
			day: '2-digit',
			hour: '2-digit',
			minute: '2-digit',
			second: '2-digit',
			hour12: false,
			timeZone: 'UTC'
		}) + ' UTC'
	)
}

/**
 * calculate duration between two dates
 * @param {Date} start - start time
 * @param {Date} end - end time
 * @returns {string} formatted duration
 */
function calculateDuration(start, end) {
	const durationMs = end.getTime() - start.getTime()
	const seconds = Math.floor(durationMs / 1000)
	const minutes = Math.floor(seconds / 60)
	const hours = Math.floor(minutes / 60)

	if (hours > 0) {
		return `${hours}h ${minutes % 60}m ${seconds % 60}s`
	} else if (minutes > 0) {
		return `${minutes}m ${seconds % 60}s`
	} else {
		return `${seconds}s`
	}
}

async function urlsToPdf() {
	const articles = getArticlesFromJson()

	if (!Array.isArray(articles) || articles.length === 0) {
		throw new Error('Articles must be a non-empty array')
	}

	// è®°å½•å¼€å§‹æ—¶é—´
	const startTime = new Date()
	console.log(`\nğŸš€ PDF generation started at: ${formatTimestamp(startTime)}`)
	console.log(`ğŸ“‹ Processing ${articles.length} articles...`)

	try {
		console.log('[1/6] Launching Chromium â€¦')
		const browser = await chromium.launch() // headless: false can be adjusted

		// count success and failure
		let successCount = 0
		let failureCount = 0
		const failedUrls = []

		for (let i = 0; i < articles.length; i++) {
			const article = articles[i]
			const url = article.url
			const sourceDomain = article.source_domain
			const refererUrl = `https://${sourceDomain}`

			console.log(`\nProcessing ${i + 1}/${articles.length} URL: ${url}`)

			try {
				const page = await browser.newPage({
					userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
					extraHTTPHeaders: { referer: refererUrl }
				})

				// Listen to all image requests, print status
				page.on('response', res => {
					const responseUrl = res.url()
					if (responseUrl.includes('images.theconversation.com/files')) {
						console.log(`[IMG] ${res.status()}  ${responseUrl.split('/').pop().split('?')[0]}`)
					}
				})

				// add retry mechanism
				let retryCount = 0
				const maxRetries = 2
				let pageLoaded = false

				while (retryCount <= maxRetries && !pageLoaded) {
					try {
						console.log(`[2/6] Navigating to target page (attempt ${retryCount + 1}/${maxRetries + 1}) â€¦`)
						await page.goto(url, {
							waitUntil: 'domcontentloaded',
							timeout: 30000
						})
						pageLoaded = true
						console.log('[3/6] Page DOM loaded, starting lazy loading â€¦')
					} catch (gotoError) {
						retryCount++
						if (retryCount <= maxRetries) {
							console.log(`âš ï¸  Navigation failed, retrying... (${retryCount}/${maxRetries})`)
							console.log(`   Error: ${gotoError.message}`)
							await page.waitForTimeout(2000) // wait 2 seconds before retrying
						} else {
							throw gotoError // retry count exceeded, throw error
						}
					}
				}

				// check if page is loaded properly
				const pageTitle = await page.title()
				console.log(`ğŸ“„ Page title: ${pageTitle}`)

				// check if page content is long enough
				const bodyText = await page.textContent('body')
				if (bodyText.length < 100) {
					throw new Error('Page content seems too short, might not have loaded properly')
				}

				// Scroll to the bottom
				await page.evaluate(() => {
					window.scrollTo({ top: document.body.scrollHeight, behavior: 'smooth' })
				})
				await page.waitForTimeout(10000)
				console.log('[4/6] Scrolling back to top, waiting for last image to appear in viewport â€¦')
				await page.evaluate(() => window.scrollTo({ top: 0 }))

				// Wait for the last figure image
				let prev = 0,
					curr
				do {
					prev = curr || 0
					await page.waitForTimeout(3000)
					curr = await page.locator('figure img[src*="files"]').count()
					console.log(`[lazy] Current ${curr} images`)
				} while (curr > prev)

				console.log(`[5/6] Total ${curr} <figure> images rendered.`)

				// Generate file name
				const urlObj = new URL(url)
				const filename = urlObj.pathname.split('/').pop() || 'page'
				const cleanFilename = filename.replace(/[^a-zA-Z0-9\-_]/g, '_')
				const pdfPath = `${outputDir}${cleanFilename}.pdf`

				// Generate PDF
				console.log('[6/6] Generating PDF â€¦')
				const pdfBuffer = await page.pdf({
					path: pdfPath,
					format: 'A4',
					printBackground: true,
					margin: { top: '1cm', bottom: '1cm', left: '1cm', right: '1cm' }
				})

				console.log(`âœ… PDF saved: ${pdfPath} (${(pdfBuffer.length / 1024).toFixed(1)} KB)`)
				await page.close()

				successCount++
				console.log(`âœ… Successfully processed URL ${i + 1}/${articles.length}`)
			} catch (urlError) {
				failureCount++
				failedUrls.push({
					url,
					error: urlError.message,
					retryCount: retryCount || 0,
					sourceDomain: sourceDomain
				})
				console.error(`âŒ Failed to process URL ${i + 1}/${articles.length}: ${url}`)
				console.error(`   âš ï¸  Error: ${urlError.message}`)
				console.error(`   ğŸ”„ Retry attempts: ${retryCount || 0}`)
				console.log(`   â­ï¸  Skipping to next URL...`)
			}
		}

		await browser.close()

		// è®°å½•ç»“æŸæ—¶é—´
		const endTime = new Date()
		const totalDuration = calculateDuration(startTime, endTime)

		// output final summary
		console.log(`\nğŸ“Š Processing Summary:`)
		console.log(`âœ… Successfully processed: ${successCount} URLs`)
		console.log(`âŒ Failed to process: ${failureCount} URLs`)
		console.log(`ğŸ“ˆ Success rate: ${((successCount / articles.length) * 100).toFixed(1)}%`)
		console.log(`ğŸ“„ Total URLs processed: ${articles.length}`)
		console.log(`\nâ° Time Information:`)
		console.log(`ğŸš€ Started at: ${formatTimestamp(startTime)}`)
		console.log(`ğŸ Finished at: ${formatTimestamp(endTime)}`)
		console.log(`â±ï¸  Total duration: ${totalDuration}`)

		if (failedUrls.length > 0) {
			console.log(`\nğŸ” Failed URLs Details:`)
			failedUrls.forEach((item, index) => {
				console.log(`   ${index + 1}. ğŸ”— ${item.url}`)
				console.log(`      âš ï¸  Error: ${item.error}`)
				console.log(`      ğŸ”„ Retry attempts: ${item.retryCount}`)
				console.log(`      ğŸŒ Source domain: ${item.sourceDomain}`)
			})
		}

		console.log(`\nğŸ‰ Processing completed!`)
		return { successCount, failureCount, failedUrls, totalUrls: articles.length, startTime, endTime, duration: totalDuration }
	} catch (error) {
		console.error('âŒ url-to-pdf processing error:', error)
		process.exit(1)
	}
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
	// if (import.meta.url) {
	console.log(`import.meta.url: ${import.meta.url}`)
	urlsToPdf()
		.then(result => {
			console.log(`\nğŸ url-to-pdf complete!`)
			console.log(`ğŸ“Š Final Results:`)
			console.log(`   ğŸ“„ Total URLs: ${result.totalUrls}`)
			console.log(`   âœ… Success: ${result.successCount}`)
			console.log(`   âŒ Failed: ${result.failureCount}`)
			console.log(`   ğŸ“ˆ Success Rate: ${((result.successCount / result.totalUrls) * 100).toFixed(1)}%`)
			console.log(`   â±ï¸  Total Duration: ${result.duration}`)
		})
		.catch(error => {
			console.error('âŒ url-to-pdf failed:', error)
			process.exit(1)
		})
}

export { urlsToPdf }

